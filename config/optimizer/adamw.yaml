_target_: torch.optim.AdamW

lr: ${learning_rate}
betas: [0.9, 0.999]
weight_decay: 0